#!/usr/bin/env python
'''
Copyright (C) 2015 - Swedish Meteorological and Hydrological Institute (SMHI)

This file is part of RAVE.

RAVE is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

RAVE is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with RAVE.  If not, see <http://www.gnu.org/licenses/>.
'''
## Command-line tool for creating acrr compoisites

## @file
## @author Anders Henja, SMHI
## @date 2015-04-13

import sys,string,os,datetime
import odim_source
import rave_dom_db
import rave_pgf_logger
import rave_tile_registry
import _raveio, _acrr, _cartesianvolume, _cartesian, _rave
from compositing import compositing
from tiled_compositing import tiled_compositing

logger = rave_pgf_logger.rave_pgf_stdout_client()

from rave_defines import CENTER_ID, GAIN, OFFSET, MERGETERMS, RAVE_PGF_QUALITY_FIELD_REPROCESSING

ravebdb = None
try:
  import rave_bdb
  ravebdb = rave_bdb.rave_bdb()
except:
  pass


def generate_comp(filepath, pattern, fdate, ftime, areaid="allbltgmaps_4000", opath="/tmp", 
                  detectors="ropo,beamb,overshooting,distance", ignore_malfunc=True, 
                  quantity="DBZH", product="pcappi", selectionMethod="NEAREST_RADAR", 
                  height=1000.0, range=200000.0, elangle=0.0, ctfilter=True, 
                  qitotal_field=None, prodpar=None, zr_a=200.0, zr_b=1.5):
  import glob
  filename = "%s/%s_comp_%s%s.h5"%(opath,areaid,fdate,ftime)
  if os.path.exists(filename):
    return filename
  files = glob.glob("%s/%s"%(filepath, pattern)) #se*_pvol*.h5
  if len(files) == 0:
    logger.warn("No files found for %s/%s"%(filepath, pattern))
    return filename
  comp = compositing(ravebdb)
  comp.height = height
  comp.elangle = elangle
  comp.range = range
  comp.nodata = 255
  comp.undetect = 0
  comp.filenames = files
  comp.detectors=string.split(detectors,",")
  comp.ignore_malfunc=ignore_malfunc
  comp.quantity = quantity
  comp.gain = GAIN
  comp.offset = OFFSET
  comp.set_product_from_string(product)
  comp.set_method_from_string(selectionMethod)
  comp.applyctfilter = ctfilter
  comp.applygra = False 
  comp.zr_A = zr_a
  comp.zr_b = zr_b
  comp.qitotal_field=qitotal_field
  comp.prodpar = prodpar
  
  comp.reprocess_quality_field = False

  comp = tiled_compositing(comp,  mp_process_qc=True)

  result = comp.generate(fdate, ftime, areaid)
  
  rio = _raveio.new()
  rio.object = result
  rio.filename = filename
  rio.save()
  
  return filename

def generate_acrr(files, opath, areaid, etime, edate, zr_a=200.0, zr_b=1.6, 
                  quantity="DBZH", accept=0.0, distancefield="se.smhi.composite.distance.radar", 
                  interval=12, N=13, adjustmentfile=None):
  acrrproduct = None
  
  acrr = _acrr.new()
  acrr.nodata = -1.0
  acrr.undetect = 0.0
  acrr.quality_field_name = distancefield

  filename = "%s/acrr_%dH_%s_%s%s.h5"%(opath, interval, areaid, edate, etime[:4])
  if os.path.exists(filename):
    return

  for fname in files:
    obj = None
    try:
      rio = _raveio.open(fname)
      obj = rio.object
    except Exception,e:
      continue

    if _cartesianvolume.isCartesianVolume(obj):
      obj = obj.getImage(0)
    
    obj.getParameter("DBZH").nodata = 255.0
    if not _cartesian.isCartesian(obj):
      raise AttributeError, "Must call plugin with cartesian products"

    if acrrproduct == None:
      acrrproduct = _cartesian.new()
      acrrproduct.xscale = obj.xscale
      acrrproduct.yscale = obj.yscale
      acrrproduct.areaextent = obj.areaextent
      acrrproduct.projection = obj.projection
      acrrproduct.product = obj.product
      acrrproduct.source = obj.source
      acrrproduct.time = etime
      acrrproduct.date = edate

    if obj.xscale != acrrproduct.xscale or obj.yscale != acrrproduct.yscale or \
       obj.projection.definition != acrrproduct.projection.definition:
      raise AttributeError, "Scale or projdef inconsistancy for used area"

    par = obj.getParameter(quantity)
    if par == None:
      logger.warn("Could not find parameter (%s) for %s %s"%(quantity, obj.date, obj.time))
    else:
      if par.getQualityFieldByHowTask(distancefield) != None:
        acrr.sum(par, zr_a, zr_b)

  # accept, N, hours
  if not acrr.isInitialized():
    logger.info("No files can be found for acrr accumulation")
    return None
  
  acrrparam = acrr.accumulate(accept, N, interval)
  acrrproduct.addParameter(acrrparam)

  rio = _raveio.new()
  rio.object = acrrproduct
  rio.filename = filename
  rio.save()

def run_acrr_composite_generation(vpath, cpath, opath, areaid, interval, filesPerHour, 
                                  acceptableLoss, startdate, enddate, pattern, 
                                  distancefield="se.smhi.composite.distance.radar", 
                                  detectors="ropo,beamb,overshooting,distance", ignore_malfunc=True, 
                                  product="pcappi", selectionMethod="NEAREST_RADAR", height=1000.0, range=200000.0, elangle=0.0,
                                  ctfilter=True, qitotal_field=None, prodpar=None, zr_a=200.0, zr_b=1.6):
  filePeriod = 60/filesPerHour
  N = interval * filesPerHour + 1
  currdt = startdate
  files = []
  while currdt <= enddate:
    volumepath = "%s/%s"%(vpath,currdt.strftime("%m/%d/%H/%M"))
    filename = generate_comp(volumepath, pattern, currdt.strftime("%Y%m%d"), currdt.strftime("%H%M00"), 
                             areaid, cpath, detectors, ignore_malfunc, "DBZH", product,
                             selectionMethod, height, range, elangle, ctfilter, qitotal_field, prodpar,
                             zr_a, zr_b)
    files.append(filename)
    
    if len(files) == N:
      print "Generating ACRR product for %s"%currdt.strftime("%Y%m%d%H%M")
      generate_acrr(files, opath, areaid, currdt.strftime("%H%M00"), currdt.strftime("%Y%m%d"), zr_a, zr_b, "DBZH", 
                    acceptableLoss, distancefield, interval, N)
      files=[filename]

        
    currdt = currdt + datetime.timedelta(seconds=filePeriod*60)

if __name__=="__main__":
  from optparse import OptionParser
  START_PERIOD="201410010000"
  END_PERIOD="201411010000"
  AREA="allbltgmaps_4000"
  INTERVAL=12 #HOURS
  FILES_PER_HOUR=4
  ZR_a=200.0
  ZR_b=1.5
  FT_UTC=6
  DISTANCE_FIELD="se.smhi.composite.distance.radar"
  ACCEPTABLE_LOSS=0
  N = INTERVAL * FILES_PER_HOUR + 1
  VOLUME_PATH="/storage/baltrad/data/2014_all"
  COMPOSITE_PATH="/storage/baltrad/acrr/composites"
  ACRR_PATH="/storage/baltrad/acrr"
  startdt = datetime.datetime.strptime(START_PERIOD, "%Y%m%d%H%M")
  enddt = datetime.datetime.strptime(END_PERIOD, "%Y%m%d%H%M")
  currdt = startdt
  minuteinterval = 60 / FILES_PER_HOUR
 
  usage = "usage: %prog --input=<input path> --startdt=<start datetime> --enddt=<end datetime> --pattern=<pattern> [--area=<area>] [--hours=hours] "
  usage += "\nGenerates acrr composites directly from polar scans and volumes."
  parser = OptionParser(usage=usage)

  parser.add_option("-i", "--input", dest="inputpath", default=VOLUME_PATH,
                    help="Locating where file searching should be started. Expected subdirectory format is <yyyy>/<MM>/<dd>/<HH>/<mm>")

  parser.add_option("-c", "--coutput", dest="compositepath", default=COMPOSITE_PATH,
                    help="Locating where composites should be placed. Expected subdirectory format is <yyyy>/<MM>/<dd>/<HH>/<mm>")

  parser.add_option("-o", "--output", dest="outputpath", default=ACRR_PATH,
                    help="Locating where acrr products should be placed. Expected subdirectory format is <yyyy>/<MM>/<dd>/<HH>/<mm>")

  parser.add_option("-S", "--startdt", dest="startdt", default=START_PERIOD,
                    help="Start date/time. Format is <yyyy><MM><dd><HH><mm>.")

  parser.add_option("-E", "--enddt", dest="enddt", default=END_PERIOD,
                    help="End date/time. Format is <yyyy><MM><dd><HH><mm>.")

  parser.add_option("-p", "--pattern", dest="pattern", default="*pvol*.h5",
                    help="File pattern to search for, e.g. --pattern='se*pvol*.h5'.")

  parser.add_option("-a", "--area", dest="area", default="allbltgmaps_4000",
                    help="Name of Cartesian area to which to generate the composite.")

  parser.add_option("-H", "--hours", dest="hours", type="int", default=12,
                    help="Number of hours that should be included in each accumulation period, either 1,2,3,4,6,8,12 or 24. Default is 12")

  (options, args) = parser.parse_args()
  
  print "Running with:"
  print "Inputpath: %s"%options.inputpath
  print "Composite path: %s"%options.compositepath
  print "Acrr path: %s"%options.outputpath
  print "Datetime: %s -> %s"%(options.startdt, options.enddt)
  print "Pattern: %s"%options.pattern
  print "Area: %s"%options.area
  print "Hours: %d"%options.hours 
  
  #run_acrr_composite_generation(vpath, cpath, areaid, interval, filesPerHour, 
  #                                acceptableLoss, startdate, enddate, distancefield="se.smhi.composite.distance.radar", 
  #                                detectors="ropo,beamb,overshooting,distance", ignore_malfunc=True, 
  #                                product="pcappi", selectionMethod="NEAREST_RADAR", height=1000.0, range=200000.0, elangle=0.0,
  #                                ctfilter=True, qitotal_field=None, prodpar=None, zr_a=200.0, zr_b=1.6):
  run_acrr_composite_generation(options.inputpath, options.compositepath, options.outputpath, options.area, options.hours, 
                                FILES_PER_HOUR, ACCEPTABLE_LOSS,
                                datetime.datetime.strptime(options.startdt, "%Y%m%d%H%M"), 
                                datetime.datetime.strptime(options.enddt, "%Y%m%d%H%M"), 
                                options.pattern)
  #def run_composite_generation(fpath, areaid, interval, filesPerHour, distanceField, acceptableLoss, startdate, enddate, zr_a=200.0, zr_b=1.6):
    #  startdt = datetime.datetime.strptime(startdate, "%Y%m%d%H%M") - datetime.timedelta(seconds=interval*3600)
#  enddt = datetime.datetime.strptime(enddate, "%Y%m%d%H%M")

    
  